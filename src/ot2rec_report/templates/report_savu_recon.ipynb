{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f3b12f-45eb-4711-a1f2-2b0b6e126eca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Savu Reconstruction\n",
    "\n",
    "Reconstruction was performed with Savu 4.0.\n",
    "\n",
    "Please cite:\n",
    "\n",
    "1. Wadeson, N and Basham, M. Savu: A Python-based, MPI Framework for Simultaneous Processing of Multiple, N-dimensional, Large Tomography Datasets. *arXiv* **1610.08015**. (2016)\n",
    "2. Wadeson, N, Verschoyle, J, Kazantsev, D., et al. DiamondLightSource/Savu: Version 4.0. *Zenodo*. (2021) [DOI](https://doi.org/10.5281/zenodo.5095360) 10.5281/zenodo.5095360.\n",
    "3. The HDF Group. Hierarchical Data Format, version 5. (1997-2016)\n",
    "4. Walker, D and Dongarra, J. MPI: a standard message passing interface. *Supercomputer* **12**: 56-68. (1996)\n",
    "5. Van Aarle, W, Palenstijn, W, Cant, J, et al. Fast and flexible X-ray tomography using the ASTRA toolbox. *Optics express* **24(22)**: 25129-25147. (2016)\n",
    "6. Van Aarle, W, Palenstijn, W, De Beenhouwer, J, et al. The ASTRA Toolbox: A platform for advanced algorithm development in electron tomography. *Ultramicroscopy* **157**: 35-47. (2015)\n",
    "7. Palenstijn, WJ and Batenburg, KJ and Sijbers, J. Performance improvements for iterative electron tomography reconstruction using graphics processing units (GPUs). *JSB* **176(2)** 250-253. (2011)\n",
    "\n",
    "\n",
    "For more information, please see https://savu.readthedocs.io/en/latest/\n",
    "\n",
    "<b>Note</b>\n",
    "\n",
    "Savu was developed by the X-ray tomography community, so the conventional relationship between grey values and density is reversed compared to EM, i.e., the colours are reversed. The visualisations in this report have had their colours inverted to match the EM convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1da67c-e48b-41d8-8194-8b46a220c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter as gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf481c04",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "raises-exception",
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def print_recon_algo():\n",
    "    \"\"\"Print Reconstruction algorithm used\"\"\"\n",
    "    savu_yaml = f\"{os.getcwd()}/{proj_name}_savurecon.yaml\"\n",
    "\n",
    "    try:\n",
    "        with open(savu_yaml, \"r\") as f:\n",
    "            output = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "            algorithm = output[\"Savu\"][\"setup\"][\"algorithm\"]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{savu_yaml} not found, cannot find algorithm used\")\n",
    "\n",
    "    printmd(f\"Reconstruction algorithm used: {algorithm}\")\n",
    "\n",
    "\n",
    "print_recon_algo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d22f06b",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def get_central_slices(img_data):\n",
    "    # Find central slices\n",
    "    z_central = int(img_data.shape[0] / 2)\n",
    "    y_central = int(img_data.shape[1] / 2)\n",
    "    x_central = int(img_data.shape[2] / 2)\n",
    "\n",
    "    # Calculate number of slices to add\n",
    "    zxy_add = (np.array(img_data.shape) * 0.0025).astype(int)\n",
    "    zxy_add[zxy_add < 1] = 1\n",
    "\n",
    "    # xy, yz, xz image data\n",
    "    xy_data = img_data[z_central - zxy_add[0] : z_central + zxy_add[0], :, :].sum(\n",
    "        axis=0\n",
    "    )\n",
    "    yz_data = img_data[:, x_central - zxy_add[1] : x_central + zxy_add[1], :].sum(\n",
    "        axis=1\n",
    "    )\n",
    "    xz_data = img_data[:, :, y_central - zxy_add[2] : y_central + zxy_add[2]].sum(\n",
    "        axis=2\n",
    "    )\n",
    "\n",
    "    return [xy_data, yz_data, xz_data]\n",
    "\n",
    "\n",
    "def show_tomogram(tomo_fname):\n",
    "    \"\"\"tomo_fname can be 3-D .mrc, 3-D .tiff, or stack of 2-D tiffs\"\"\"\n",
    "\n",
    "    # Import image data\n",
    "    if tomo_fname.endswith(\".mrc\"):\n",
    "        with mrcfile.open(tomo_fname) as mrc:\n",
    "            img_data = mrc.data\n",
    "\n",
    "    elif os.path.isdir(tomo_fname):\n",
    "        volume = []\n",
    "        for xy_slice in os.listdir(tomo_fname):\n",
    "            volume.append(tifffile.imread(f\"{tomo_fname}/{xy_slice}\").data)\n",
    "        img_data = np.stack(volume)\n",
    "\n",
    "    elif tomo_fname.endswith(\".tif\"):\n",
    "        img_data = tifffile.imread(tomo_fname)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Tomogram cannot be read. Please use a 3D tiff, mrc or stack of 2D Tiffs\"\n",
    "        )\n",
    "\n",
    "    xy_data, yz_data, xz_data = get_central_slices(img_data)\n",
    "    data_flattened = np.hstack(\n",
    "        (xy_data.flatten(), yz_data.flatten(), xz_data.flatten())\n",
    "    )\n",
    "\n",
    "    # Show central slices in xy, yz, xz\n",
    "    plt.figure(figsize=(10, 3.5))\n",
    "    plt.suptitle(os.path.basename(tomo_fname))\n",
    "    titles = [\"x-y\", \"y-z\", \"x-z\"]\n",
    "\n",
    "    for i, data in enumerate([xy_data, yz_data, xz_data]):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.imshow(\n",
    "            data,\n",
    "            cmap=\"Greys\",\n",
    "            vmin=np.percentile(data_flattened[data_flattened > 0], 10),\n",
    "            vmax=np.percentile(data_flattened[data_flattened > 0], 95),\n",
    "        )\n",
    "        plt.title(titles[i])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc0dde",
   "metadata": {
    "tags": [
     "raises-exception",
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def get_tomogram_filenames():\n",
    "    # Get Savu mdout\n",
    "    try:\n",
    "        savu_mdout = f\"{os.getcwd()}/{proj_name}_savurecon_mdout.yaml\"\n",
    "    except FileNotFoundError:\n",
    "        print(\n",
    "            f\"{proj_name}_savurecon_mdout.yaml not found, cannot find tomogram filenames.\"\n",
    "        )\n",
    "\n",
    "    with open(savu_mdout, \"r\") as f:\n",
    "        output = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "        tomogram_filenames = output[\"tomogram\"].values()\n",
    "\n",
    "    return tomogram_filenames\n",
    "\n",
    "\n",
    "tomogram_filenames = get_tomogram_filenames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64745d4e",
   "metadata": {},
   "source": [
    "#### Tomogram thumbnails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa9e50",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "hide",
     "raises_exception"
    ]
   },
   "outputs": [],
   "source": [
    "# Show thumbnails of the tomograms\n",
    "\n",
    "for tomogram in tomogram_filenames:\n",
    "    show_tomogram(tomogram)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
